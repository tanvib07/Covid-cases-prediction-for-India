{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-MAJOR-JUNE (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load dataset from - https://covid.ourworldindata.org/data/owid-covid-data.csv<br>\n",
    "2. Subset only those rows that have “India” in the “location” column(This subsetted\n",
    "dataframe has to be used for modelling)<br>\n",
    "3. Handle Missing values:<br>\n",
    "a. If there are null values in continuous numerical column, replace the null values by\n",
    "the mean of that column<br>\n",
    "b. If there are null values in ordinal numerical column, replace the null values by the\n",
    "mode of that column<br>\n",
    "c. If there are null values in categorical column, replace the null values by the mode\n",
    "of that column<br>\n",
    "d. If more than 50%the values in a column are null, then drop that entire column<br>\n",
    "\n",
    "4. Univariate Analysis:<br>\n",
    "a. Draw histograms of 10 feature columns<br>\n",
    "b. Find mean, median and mode of each column<br>\n",
    "5. Bivariate Analysis:<br>\n",
    "a. Draw scatter plots of target column versus 10 features<br>\n",
    "b. Draw line plots of target column versus 10 features<br>\n",
    "\n",
    "6. Convert date column to ordinal<br>\n",
    "a. Code:<br>\n",
    "import datetime as dt<br>\n",
    "df[\"date\"]=pd.to_datetime(df[\"date\"])<br>\n",
    "df[\"date\"]=df[\"date\"].map(dt.datetime.toordinal)<br>\n",
    "\n",
    "7. Drop useless categorical columns, and convert useful categorical to numerical by\n",
    "labelencoder<br>\n",
    "8. Select “total_cases” column as the target variable<br>\n",
    "9. Select the other columns as the features(NOTE: the “date” column has to be\n",
    "compulsorily in the features)<br>\n",
    "10. Perform train-test split<br>\n",
    "11. Modelling:<br>\n",
    "a. Linear Regression<br>\n",
    "b. Random Forest Regressor<br>\n",
    "12. Get accuracy<br>\n",
    "13. Predict Total case for a new date<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"processed_covid_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'iso_code', 'continent', 'location', 'date',\n",
       "       'total_cases', 'new_cases', 'total_deaths', 'new_deaths',\n",
       "       'total_cases_per_million', 'new_cases_per_million',\n",
       "       'total_deaths_per_million', 'new_deaths_per_million', 'new_tests',\n",
       "       'total_tests', 'total_tests_per_thousand', 'new_tests_per_thousand',\n",
       "       'new_tests_smoothed', 'new_tests_smoothed_per_thousand',\n",
       "       'tests_per_case', 'positive_rate', 'tests_units', 'stringency_index',\n",
       "       'population', 'population_density', 'median_age', 'aged_65_older',\n",
       "       'aged_70_older', 'gdp_per_capita', 'extreme_poverty',\n",
       "       'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers',\n",
       "       'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand',\n",
       "       'life_expectancy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_col_list = ['Unnamed: 0', 'iso_code', 'continent', 'location','population', 'population_density', 'median_age', \n",
    "                   'aged_65_older','aged_70_older', 'gdp_per_capita', 'extreme_poverty','cardiovasc_death_rate',\n",
    "                   'diabetes_prevalence', 'female_smokers','male_smokers', 'handwashing_facilities',\n",
    "                   'hospital_beds_per_thousand','life_expectancy']\n",
    "#We drop these columns as the data in it is a single value which won't help to efficiently derive the desired output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1 = data1.drop(delete_col_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221 entries, 0 to 220\n",
      "Data columns (total 19 columns):\n",
      "date                               221 non-null int64\n",
      "total_cases                        221 non-null float64\n",
      "new_cases                          221 non-null float64\n",
      "total_deaths                       221 non-null float64\n",
      "new_deaths                         221 non-null float64\n",
      "total_cases_per_million            221 non-null float64\n",
      "new_cases_per_million              221 non-null float64\n",
      "total_deaths_per_million           221 non-null float64\n",
      "new_deaths_per_million             221 non-null float64\n",
      "new_tests                          221 non-null float64\n",
      "total_tests                        221 non-null float64\n",
      "total_tests_per_thousand           221 non-null float64\n",
      "new_tests_per_thousand             221 non-null float64\n",
      "new_tests_smoothed                 221 non-null float64\n",
      "new_tests_smoothed_per_thousand    221 non-null float64\n",
      "tests_per_case                     221 non-null float64\n",
      "positive_rate                      221 non-null float64\n",
      "tests_units                        221 non-null object\n",
      "stringency_index                   221 non-null float64\n",
      "dtypes: float64(17), int64(1), object(1)\n",
      "memory usage: 32.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting tests_units to numerical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221 entries, 0 to 220\n",
      "Data columns (total 19 columns):\n",
      "date                               221 non-null int64\n",
      "total_cases                        221 non-null float64\n",
      "new_cases                          221 non-null float64\n",
      "total_deaths                       221 non-null float64\n",
      "new_deaths                         221 non-null float64\n",
      "total_cases_per_million            221 non-null float64\n",
      "new_cases_per_million              221 non-null float64\n",
      "total_deaths_per_million           221 non-null float64\n",
      "new_deaths_per_million             221 non-null float64\n",
      "new_tests                          221 non-null float64\n",
      "total_tests                        221 non-null float64\n",
      "total_tests_per_thousand           221 non-null float64\n",
      "new_tests_per_thousand             221 non-null float64\n",
      "new_tests_smoothed                 221 non-null float64\n",
      "new_tests_smoothed_per_thousand    221 non-null float64\n",
      "tests_per_case                     221 non-null float64\n",
      "positive_rate                      221 non-null float64\n",
      "tests_units                        221 non-null int32\n",
      "stringency_index                   221 non-null float64\n",
      "dtypes: float64(17), int32(1), int64(1)\n",
      "memory usage: 32.1 KB\n"
     ]
    }
   ],
   "source": [
    "le.fit(data1['tests_units'])\n",
    "data1['tests_units']=le.transform(data1['tests_units'])\n",
    "data1.info()\n",
    "#All are numerical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target and feature data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data1.drop(['total_cases'],axis=1).values\n",
    "y = data1['total_cases'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.96618901e+04  5.96620000e+04]\n",
      " [ 1.15519060e+06  1.15519100e+06]\n",
      " [ 9.61683772e+04  9.61690000e+04]\n",
      " [ 2.91519761e+01  2.90000000e+01]\n",
      " [ 5.48318268e+05  5.48318000e+05]\n",
      " [ 1.38845113e+05  1.38845000e+05]\n",
      " [ 2.91516688e+00  3.00000000e+00]\n",
      " [ 7.33391999e+01  7.30000000e+01]\n",
      " [ 5.73367975e+00  6.00000000e+00]\n",
      " [ 2.76398367e-03  0.00000000e+00]\n",
      " [ 4.92708771e+02  4.92000000e+02]\n",
      " [ 2.87608525e+00  3.00000000e+00]\n",
      " [-1.39852854e-02  0.00000000e+00]\n",
      " [ 3.66945911e+05  3.66946000e+05]\n",
      " [ 5.82466225e+00  5.00000000e+00]\n",
      " [ 1.00383169e+06  1.00383200e+06]\n",
      " [ 2.86578822e+05  2.86579000e+05]\n",
      " [ 1.19291448e+06  1.19291500e+06]\n",
      " [ 4.25281352e+05  4.25282000e+05]\n",
      " [ 1.07105561e+03  1.07100000e+03]\n",
      " [ 1.43783150e+04  1.43780000e+04]\n",
      " [ 4.93905765e+04  4.93910000e+04]\n",
      " [ 3.99802537e+04  3.99800000e+04]\n",
      " [ 8.98388726e+01  9.00000000e+01]\n",
      " [ 1.25765630e+02  1.25000000e+02]\n",
      " [ 2.50963425e-02  0.00000000e+00]\n",
      " [ 2.26770730e+05  2.26770000e+05]\n",
      " [ 2.46627671e+05  2.46628000e+05]\n",
      " [ 3.73360512e+04  3.73360000e+04]\n",
      " [ 1.25101638e+05  1.25101000e+05]\n",
      " [ 2.97658087e+00  3.00000000e+00]\n",
      " [ 1.31867773e+05  1.31868000e+05]\n",
      " [ 4.42153198e+03  4.42100000e+03]\n",
      " [ 1.90825380e+06  1.90825400e+06]\n",
      " [ 5.85948807e-02  0.00000000e+00]\n",
      " [ 4.18456116e-02  0.00000000e+00]\n",
      " [ 1.73763355e+05  1.73763000e+05]\n",
      " [-2.81910603e-03  0.00000000e+00]\n",
      " [ 9.25702840e+01  9.30000000e+01]\n",
      " [ 2.66597690e+05  2.66598000e+05]\n",
      " [ 4.06683503e+03  4.06700000e+03]\n",
      " [ 1.12358711e+05  1.12359000e+05]\n",
      " [ 1.25185147e+03  1.25100000e+03]\n",
      " [ 1.03624282e+04  1.03630000e+04]\n",
      " [ 1.23863508e+06  1.23863500e+06]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr_reg.predict(x_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "LR_err = mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on processing with Linear Regression is 99.85 %\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy on processing with Linear Regression is \" + str(np.round((100-LR_err),2))+ \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.6991200e+04 5.9662000e+04]\n",
      " [1.0812494e+06 1.1551910e+06]\n",
      " [9.7116600e+04 9.6169000e+04]\n",
      " [2.0100000e+01 2.9000000e+01]\n",
      " [5.4400370e+05 5.4831800e+05]\n",
      " [1.3867670e+05 1.3884500e+05]\n",
      " [3.0000000e+00 3.0000000e+00]\n",
      " [7.2200000e+01 7.3000000e+01]\n",
      " [1.1400000e+01 6.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00]\n",
      " [4.8200000e+02 4.9200000e+02]\n",
      " [3.0000000e+00 3.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00]\n",
      " [3.6596320e+05 3.6694600e+05]\n",
      " [1.6100000e+01 5.0000000e+00]\n",
      " [1.0614938e+06 1.0038320e+06]\n",
      " [2.8961740e+05 2.8657900e+05]\n",
      " [1.1489398e+06 1.1929150e+06]\n",
      " [4.0114380e+05 4.2528200e+05]\n",
      " [9.7720000e+02 1.0710000e+03]\n",
      " [1.3483100e+04 1.4378000e+04]\n",
      " [5.0250200e+04 4.9391000e+04]\n",
      " [4.1035000e+04 3.9980000e+04]\n",
      " [6.5900000e+01 9.0000000e+01]\n",
      " [1.4520000e+02 1.2500000e+02]\n",
      " [0.0000000e+00 0.0000000e+00]\n",
      " [2.4073960e+05 2.2677000e+05]\n",
      " [2.5661820e+05 2.4662800e+05]\n",
      " [3.8788000e+04 3.7336000e+04]\n",
      " [1.3415710e+05 1.2510100e+05]\n",
      " [3.0000000e+00 3.0000000e+00]\n",
      " [1.3857750e+05 1.3186800e+05]\n",
      " [4.4598000e+03 4.4210000e+03]\n",
      " [1.8349412e+06 1.9082540e+06]\n",
      " [0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00]\n",
      " [1.8763820e+05 1.7376300e+05]\n",
      " [0.0000000e+00 0.0000000e+00]\n",
      " [6.5100000e+01 9.3000000e+01]\n",
      " [2.7933920e+05 2.6659800e+05]\n",
      " [5.6127000e+03 4.0670000e+03]\n",
      " [1.0303320e+05 1.1235900e+05]\n",
      " [1.1818000e+03 1.2510000e+03]\n",
      " [1.0758100e+04 1.0363000e+04]\n",
      " [1.3004564e+06 1.2386350e+06]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_1 = forest_reg.predict(x_test)\n",
    "print(np.concatenate((y_pred_1.reshape(len(y_pred_1),1), y_test.reshape(len(y_test),1)), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg.score(x_test,y_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "acc = explained_variance_score(y_test,y_pred_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on processing with Random Forest is 99.72 %\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy on processing with Random Forest is \" + str(np.round((100*acc),2))+ \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting cases for a new Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>total_cases_per_million</th>\n",
       "      <th>new_cases_per_million</th>\n",
       "      <th>total_deaths_per_million</th>\n",
       "      <th>new_deaths_per_million</th>\n",
       "      <th>new_tests</th>\n",
       "      <th>total_tests</th>\n",
       "      <th>total_tests_per_thousand</th>\n",
       "      <th>new_tests_per_thousand</th>\n",
       "      <th>new_tests_smoothed</th>\n",
       "      <th>new_tests_smoothed_per_thousand</th>\n",
       "      <th>tests_per_case</th>\n",
       "      <th>positive_rate</th>\n",
       "      <th>tests_units</th>\n",
       "      <th>stringency_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>737424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128314.0</td>\n",
       "      <td>3787117.0</td>\n",
       "      <td>2.7445</td>\n",
       "      <td>0.093</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>0.079</td>\n",
       "      <td>9.667</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0</td>\n",
       "      <td>10.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>737425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128314.0</td>\n",
       "      <td>3787117.0</td>\n",
       "      <td>2.7445</td>\n",
       "      <td>0.093</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>0.079</td>\n",
       "      <td>9.667</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>737426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128314.0</td>\n",
       "      <td>3787117.0</td>\n",
       "      <td>2.7445</td>\n",
       "      <td>0.093</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>0.079</td>\n",
       "      <td>9.667</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>737427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128314.0</td>\n",
       "      <td>3787117.0</td>\n",
       "      <td>2.7445</td>\n",
       "      <td>0.093</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>0.079</td>\n",
       "      <td>9.667</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>737428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128314.0</td>\n",
       "      <td>3787117.0</td>\n",
       "      <td>2.7445</td>\n",
       "      <td>0.093</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>0.079</td>\n",
       "      <td>9.667</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date  total_cases  new_cases  total_deaths  new_deaths  \\\n",
       "0  737424          0.0        0.0           0.0         0.0   \n",
       "1  737425          0.0        0.0           0.0         0.0   \n",
       "2  737426          0.0        0.0           0.0         0.0   \n",
       "3  737427          0.0        0.0           0.0         0.0   \n",
       "4  737428          0.0        0.0           0.0         0.0   \n",
       "\n",
       "   total_cases_per_million  new_cases_per_million  total_deaths_per_million  \\\n",
       "0                      0.0                    0.0                       0.0   \n",
       "1                      0.0                    0.0                       0.0   \n",
       "2                      0.0                    0.0                       0.0   \n",
       "3                      0.0                    0.0                       0.0   \n",
       "4                      0.0                    0.0                       0.0   \n",
       "\n",
       "   new_deaths_per_million  new_tests  total_tests  total_tests_per_thousand  \\\n",
       "0                     0.0   128314.0    3787117.0                    2.7445   \n",
       "1                     0.0   128314.0    3787117.0                    2.7445   \n",
       "2                     0.0   128314.0    3787117.0                    2.7445   \n",
       "3                     0.0   128314.0    3787117.0                    2.7445   \n",
       "4                     0.0   128314.0    3787117.0                    2.7445   \n",
       "\n",
       "   new_tests_per_thousand  new_tests_smoothed  \\\n",
       "0                   0.093              1125.0   \n",
       "1                   0.093              1125.0   \n",
       "2                   0.093              1125.0   \n",
       "3                   0.093              1125.0   \n",
       "4                   0.093              1125.0   \n",
       "\n",
       "   new_tests_smoothed_per_thousand  tests_per_case  positive_rate  \\\n",
       "0                            0.079           9.667          0.062   \n",
       "1                            0.079           9.667          0.062   \n",
       "2                            0.079           9.667          0.062   \n",
       "3                            0.079           9.667          0.062   \n",
       "4                            0.079           9.667          0.062   \n",
       "\n",
       "   tests_units  stringency_index  \n",
       "0            0             10.19  \n",
       "1            0              0.00  \n",
       "2            0              0.00  \n",
       "3            0              0.00  \n",
       "4            0              0.00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input the date on which you want to see the total cases count in 'yyyy-mm-dd' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert a date you would like to predict ' Input : 2020-10-10\n"
     ]
    }
   ],
   "source": [
    "test_date = input(\"Insert a date you would like to predict \"  + \"\\' Input : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "temp=test_date\n",
    "d = dt.strptime(temp, '%Y-%m-%d').date()\n",
    "d=d.toordinal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = data1.columns\n",
    "data2 = data1[col].copy()\n",
    "value = [{'date':d}]\n",
    "data2 = data2.append(value, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total test cases that on 2020-10-10 will be -->  [1691103.8]\n"
     ]
    }
   ],
   "source": [
    "temp_data= data2.ffill(axis=0)  #filling the null values in last row with date to be checked\n",
    "temp_x = temp_data.drop(['total_cases'],axis=1).values\n",
    "temp_x = temp_x[-1]\n",
    "result = forest_reg.predict([temp_x])\n",
    "print(\"The Total test cases that on\",temp ,\"will be --> \",(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
